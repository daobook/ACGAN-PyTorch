{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "def load(model, model_file):\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss_sigmoid = nn.BCEWithLogitsLoss()\n",
    "aux_loss = nn.CrossEntropyLoss()\n",
    "G, D = create_model()\n",
    "# optimizer\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "# fixed input for debugging\n",
    "fixed_z = tensor2var(torch.randn(batch_size, z_dim), ctx=ctx)  # (*, 100)\n",
    "fixed_labels = tensor2var(torch.randint(0, n_classes, (batch_size,),\n",
    "                                        dtype=torch.long), ctx=ctx)\n",
    "\n",
    "def load_model(epoch, G=G, D=D):\n",
    "    if epoch < 0:\n",
    "        return G, D\n",
    "    else:\n",
    "        G = load(G, f'results/G{epoch}.pt')\n",
    "        D = load(D, f'results/D{epoch}.pt')\n",
    "        return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_epoch = -1\n",
    "G, D = load_model(epoch=load_epoch)\n",
    "import torch\n",
    "torch.cuda.empty_cache() # 清空 GPU 缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed [0:00:19.587910], G_step [0/15000], D_step[0/15000], d_loss: 5.5627, g_loss: 5.4476, Acc: 0.0938\n",
      "Elapsed [0:00:17.325533], G_step [10/15000], D_step[10/15000], d_loss: 5.3165, g_loss: 7.9280, Acc: 0.1562\n",
      "Elapsed [0:00:16.998439], G_step [20/15000], D_step[20/15000], d_loss: 5.5939, g_loss: 7.7659, Acc: 0.0312\n",
      "Elapsed [0:00:17.582046], G_step [30/15000], D_step[30/15000], d_loss: 5.2078, g_loss: 8.0218, Acc: 0.1875\n",
      "Elapsed [0:00:17.495244], G_step [40/15000], D_step[40/15000], d_loss: 5.2776, g_loss: 8.1110, Acc: 0.1875\n",
      "Elapsed [0:00:17.365253], G_step [50/15000], D_step[50/15000], d_loss: 5.3861, g_loss: 8.3730, Acc: 0.1250\n",
      "Elapsed [0:00:17.674589], G_step [60/15000], D_step[60/15000], d_loss: 5.2897, g_loss: 7.0865, Acc: 0.1875\n",
      "Elapsed [0:00:17.889655], G_step [70/15000], D_step[70/15000], d_loss: 5.4459, g_loss: 9.3411, Acc: 0.1562\n",
      "Elapsed [0:00:17.411195], G_step [80/15000], D_step[80/15000], d_loss: 5.1701, g_loss: 7.5020, Acc: 0.2500\n",
      "Elapsed [0:00:17.585452], G_step [90/15000], D_step[90/15000], d_loss: 5.2914, g_loss: 8.3941, Acc: 0.1250\n",
      "Elapsed [0:00:17.778526], G_step [100/15000], D_step[100/15000], d_loss: 5.2181, g_loss: 8.1988, Acc: 0.1875\n",
      "Elapsed [0:00:16.814082], G_step [110/15000], D_step[110/15000], d_loss: 5.4760, g_loss: 7.3696, Acc: 0.0625\n",
      "Elapsed [0:00:17.131394], G_step [120/15000], D_step[120/15000], d_loss: 5.2221, g_loss: 8.7139, Acc: 0.1875\n",
      "Elapsed [0:00:18.243206], G_step [130/15000], D_step[130/15000], d_loss: 5.1121, g_loss: 8.0116, Acc: 0.2500\n",
      "Elapsed [0:00:18.516144], G_step [140/15000], D_step[140/15000], d_loss: 5.1269, g_loss: 8.3718, Acc: 0.2500\n",
      "Elapsed [0:00:18.798037], G_step [150/15000], D_step[150/15000], d_loss: 5.1279, g_loss: 8.0467, Acc: 0.2188\n",
      "Elapsed [0:00:18.856254], G_step [160/15000], D_step[160/15000], d_loss: 5.2456, g_loss: 8.2349, Acc: 0.1562\n",
      "Elapsed [0:00:18.859632], G_step [170/15000], D_step[170/15000], d_loss: 5.3291, g_loss: 6.6725, Acc: 0.1875\n",
      "Elapsed [0:00:18.430844], G_step [180/15000], D_step[180/15000], d_loss: 5.4380, g_loss: 6.6587, Acc: 0.1250\n",
      "Elapsed [0:00:16.712138], G_step [190/15000], D_step[190/15000], d_loss: 5.7028, g_loss: 8.4531, Acc: 0.1875\n",
      "Elapsed [0:00:16.757917], G_step [200/15000], D_step[200/15000], d_loss: 5.2113, g_loss: 7.3898, Acc: 0.2188\n",
      "Elapsed [0:00:16.806332], G_step [210/15000], D_step[210/15000], d_loss: 5.2714, g_loss: 6.8002, Acc: 0.2812\n",
      "Elapsed [0:00:16.499478], G_step [220/15000], D_step[220/15000], d_loss: 5.2886, g_loss: 8.5655, Acc: 0.1562\n",
      "Elapsed [0:00:16.662655], G_step [230/15000], D_step[230/15000], d_loss: 5.3168, g_loss: 7.7553, Acc: 0.1562\n",
      "Elapsed [0:00:16.606624], G_step [240/15000], D_step[240/15000], d_loss: 5.1505, g_loss: 7.3112, Acc: 0.2500\n",
      "Elapsed [0:00:16.555754], G_step [250/15000], D_step[250/15000], d_loss: 5.3364, g_loss: 8.1037, Acc: 0.1875\n",
      "Elapsed [0:00:16.516664], G_step [260/15000], D_step[260/15000], d_loss: 5.5817, g_loss: 7.0659, Acc: 0.1250\n",
      "Elapsed [0:00:16.680658], G_step [270/15000], D_step[270/15000], d_loss: 5.1557, g_loss: 8.0444, Acc: 0.3125\n",
      "Elapsed [0:00:16.553652], G_step [280/15000], D_step[280/15000], d_loss: 5.7470, g_loss: 6.6182, Acc: 0.2188\n",
      "Elapsed [0:00:16.466755], G_step [290/15000], D_step[290/15000], d_loss: 5.1872, g_loss: 7.5680, Acc: 0.2500\n",
      "Elapsed [0:00:16.424090], G_step [300/15000], D_step[300/15000], d_loss: 5.1811, g_loss: 7.0372, Acc: 0.3438\n",
      "Elapsed [0:00:16.407756], G_step [310/15000], D_step[310/15000], d_loss: 5.1849, g_loss: 7.3357, Acc: 0.2500\n",
      "Elapsed [0:00:16.240685], G_step [320/15000], D_step[320/15000], d_loss: 5.4519, g_loss: 7.3556, Acc: 0.2500\n",
      "Elapsed [0:00:16.356107], G_step [330/15000], D_step[330/15000], d_loss: 5.1084, g_loss: 8.2259, Acc: 0.3125\n",
      "Elapsed [0:00:15.009781], G_step [340/15000], D_step[340/15000], d_loss: 5.2762, g_loss: 6.3602, Acc: 0.2188\n",
      "Elapsed [0:00:16.134473], G_step [350/15000], D_step[350/15000], d_loss: 5.0862, g_loss: 6.9300, Acc: 0.3438\n",
      "Elapsed [0:00:16.149756], G_step [360/15000], D_step[360/15000], d_loss: 5.3025, g_loss: 7.1968, Acc: 0.1562\n",
      "Elapsed [0:00:16.132745], G_step [370/15000], D_step[370/15000], d_loss: 4.9571, g_loss: 7.5088, Acc: 0.3438\n",
      "Elapsed [0:00:09.422447], G_step [380/15000], D_step[380/15000], d_loss: 5.2279, g_loss: 7.0224, Acc: 0.2812\n",
      "Elapsed [0:00:09.331283], G_step [390/15000], D_step[390/15000], d_loss: 5.2362, g_loss: 6.9661, Acc: 0.3750\n",
      "Elapsed [0:00:09.257293], G_step [400/15000], D_step[400/15000], d_loss: 5.2510, g_loss: 8.1872, Acc: 0.1875\n",
      "Elapsed [0:00:09.197376], G_step [410/15000], D_step[410/15000], d_loss: 5.3052, g_loss: 7.9661, Acc: 0.2188\n",
      "Elapsed [0:00:09.160929], G_step [420/15000], D_step[420/15000], d_loss: 5.9709, g_loss: 7.3011, Acc: 0.4375\n",
      "Elapsed [0:00:09.323662], G_step [430/15000], D_step[430/15000], d_loss: 5.3336, g_loss: 7.6896, Acc: 0.3750\n",
      "Elapsed [0:00:09.386509], G_step [440/15000], D_step[440/15000], d_loss: 5.1982, g_loss: 6.0502, Acc: 0.3125\n",
      "Elapsed [0:00:09.109240], G_step [450/15000], D_step[450/15000], d_loss: 4.9378, g_loss: 6.5139, Acc: 0.3750\n",
      "Elapsed [0:00:09.283342], G_step [460/15000], D_step[460/15000], d_loss: 4.9031, g_loss: 7.4883, Acc: 0.3438\n",
      "Elapsed [0:00:09.274060], G_step [470/15000], D_step[470/15000], d_loss: 5.4998, g_loss: 6.6590, Acc: 0.1875\n",
      "Elapsed [0:00:09.147372], G_step [480/15000], D_step[480/15000], d_loss: 5.0410, g_loss: 7.7295, Acc: 0.2812\n",
      "Elapsed [0:00:09.148962], G_step [490/15000], D_step[490/15000], d_loss: 7.3117, g_loss: 6.9900, Acc: 0.2812\n",
      "Elapsed [0:00:09.210753], G_step [500/15000], D_step[500/15000], d_loss: 4.7577, g_loss: 6.7859, Acc: 0.4688\n",
      "Elapsed [0:00:09.164226], G_step [510/15000], D_step[510/15000], d_loss: 6.5527, g_loss: 6.0758, Acc: 0.3125\n",
      "Elapsed [0:00:09.232792], G_step [520/15000], D_step[520/15000], d_loss: 5.3119, g_loss: 6.2656, Acc: 0.3125\n",
      "Elapsed [0:00:09.382584], G_step [530/15000], D_step[530/15000], d_loss: 5.5542, g_loss: 7.2676, Acc: 0.2812\n",
      "Elapsed [0:00:09.294554], G_step [540/15000], D_step[540/15000], d_loss: 5.1295, g_loss: 6.7890, Acc: 0.3438\n",
      "Elapsed [0:00:09.280814], G_step [550/15000], D_step[550/15000], d_loss: 4.9868, g_loss: 7.2051, Acc: 0.3438\n",
      "Elapsed [0:00:09.323721], G_step [560/15000], D_step[560/15000], d_loss: 4.9513, g_loss: 6.1704, Acc: 0.3438\n",
      "Elapsed [0:00:09.466946], G_step [570/15000], D_step[570/15000], d_loss: 5.2974, g_loss: 5.8648, Acc: 0.4375\n",
      "Elapsed [0:00:09.391957], G_step [580/15000], D_step[580/15000], d_loss: 5.2329, g_loss: 7.0944, Acc: 0.3750\n",
      "Elapsed [0:00:09.421954], G_step [590/15000], D_step[590/15000], d_loss: 4.9723, g_loss: 7.3879, Acc: 0.4062\n",
      "Elapsed [0:00:09.319497], G_step [600/15000], D_step[600/15000], d_loss: 4.9863, g_loss: 6.2523, Acc: 0.4375\n",
      "Elapsed [0:00:09.222809], G_step [610/15000], D_step[610/15000], d_loss: 5.1024, g_loss: 6.4539, Acc: 0.3750\n",
      "Elapsed [0:00:09.307814], G_step [620/15000], D_step[620/15000], d_loss: 4.4938, g_loss: 8.4964, Acc: 0.5938\n",
      "Elapsed [0:00:09.211561], G_step [630/15000], D_step[630/15000], d_loss: 4.8082, g_loss: 6.6019, Acc: 0.5312\n",
      "Elapsed [0:00:09.132755], G_step [640/15000], D_step[640/15000], d_loss: 4.8883, g_loss: 7.0006, Acc: 0.4062\n",
      "Elapsed [0:00:09.260349], G_step [650/15000], D_step[650/15000], d_loss: 4.8269, g_loss: 7.0965, Acc: 0.4688\n",
      "Elapsed [0:00:09.251871], G_step [660/15000], D_step[660/15000], d_loss: 4.8680, g_loss: 6.4971, Acc: 0.4375\n",
      "Elapsed [0:00:09.167969], G_step [670/15000], D_step[670/15000], d_loss: 5.3304, g_loss: 7.9260, Acc: 0.3438\n"
     ]
    }
   ],
   "source": [
    "epochs = 15000\n",
    "if 1:\n",
    "    for epoch in range(load_epoch+1, epochs+load_epoch+1):\n",
    "        # start time\n",
    "        start_time = time.time()\n",
    "        data_loader = data_iter()\n",
    "        for i, (real_images, labels) in enumerate(data_loader):\n",
    "            # configure input\n",
    "            real_images = tensor2var(real_images, ctx=ctx)\n",
    "            labels = tensor2var(labels, ctx=ctx) #- 1\n",
    "            # adversarial ground truths\n",
    "            valid = torch.full((real_images.size(0),), 0.9)\n",
    "            valid = tensor2var(valid, ctx=ctx)  # (*, )\n",
    "            fake = torch.full((real_images.size(0),), 0.0)\n",
    "            fake = tensor2var(fake, ctx=ctx)  # (*, )\n",
    "\n",
    "            D = D.to(f'cuda:{ctx}')\n",
    "            G = G.to(f'cuda:{ctx}').to(f'cuda:{ctx}')\n",
    "            adversarial_loss_sigmoid.to(f'cuda:{ctx}')\n",
    "            aux_loss\n",
    "\n",
    "            # ==================== Train D ==================\n",
    "            D.train()\n",
    "            G.train()\n",
    "\n",
    "            D.zero_grad()\n",
    "            # compute loss with real images\n",
    "            dis_out_real, aux_out_real = D(real_images)\n",
    "\n",
    "            adversarial_loss_sigmoid = nn.BCEWithLogitsLoss().to(f'cuda:{ctx}')\n",
    "            aux_loss = nn.CrossEntropyLoss().to(f'cuda:{ctx}')\n",
    "            d_loss_real = adversarial_loss_sigmoid(dis_out_real, valid) + aux_loss(aux_out_real, labels)\n",
    "\n",
    "            # noise z for generator\n",
    "            z = tensor2var(torch.randn(real_images.size(0), z_dim), ctx=ctx)  # *, 100\n",
    "            gen_labels = torch.randint(0, n_classes, (real_images.size(0),), dtype=torch.long)\n",
    "            gen_labels = tensor2var(gen_labels, ctx=ctx)\n",
    "\n",
    "            fake_images = G(z, gen_labels)  # (*, c, 64, 64)\n",
    "            dis_out_fake, aux_out_fake = D(fake_images)  # (*,)\n",
    "\n",
    "            d_loss_fake = adversarial_loss_sigmoid(\n",
    "                dis_out_fake, fake) + aux_loss(aux_out_fake, gen_labels)\n",
    "\n",
    "            # total d loss\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            d_loss.backward()\n",
    "            # update D\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # calculate dis accuracy\n",
    "            d_acc = compute_acc(aux_out_real, aux_out_fake, labels, gen_labels)\n",
    "            # train the generator every 5 steps\n",
    "            if i % g_num == 0:\n",
    "                # =================== Train G and gumbel =====================\n",
    "                G.zero_grad()\n",
    "                # create random noise \n",
    "                fake_images = G(z, gen_labels)\n",
    "\n",
    "                # compute loss with fake images \n",
    "                dis_out_fake, aux_out_fake = D(fake_images) # batch x n\n",
    "\n",
    "                g_loss_fake = adversarial_loss_sigmoid(dis_out_fake, valid) + \\\n",
    "                    aux_loss(aux_out_fake, gen_labels)\n",
    "\n",
    "                g_loss_fake.backward()\n",
    "                # update G\n",
    "                g_optimizer.step()\n",
    "        # log to the tensorboard\n",
    "        logger.add_scalar('d_loss', d_loss.data, epoch)\n",
    "        logger.add_scalar('g_loss_fake', g_loss_fake.data, epoch)\n",
    "        # end one epoch\n",
    "\n",
    "        # print out log info\n",
    "        if (epoch) % log_step == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "            print(\"Elapsed [{}], G_step [{}/{}], D_step[{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, Acc: {:.4f}\"\n",
    "                        .format(elapsed, epoch, epochs, epoch,\n",
    "                                epochs, d_loss.item(), g_loss_fake.item(), d_acc))\n",
    "        # sample images \n",
    "        if (epoch) % sample_step == 0:\n",
    "            G.eval()\n",
    "            # save real image\n",
    "            save_sample(sample_path + '/real_images/', real_images, epoch)\n",
    "            with torch.no_grad():\n",
    "                fake_images = G(fixed_z, fixed_labels)\n",
    "                # save fake image \n",
    "                save_sample(sample_path + '/fake_images/', fake_images, epoch)\n",
    "            # sample sample one images\n",
    "            save_sample_one_image(sample_path, real_images, fake_images, epoch)\n",
    "            torch.save(G.state_dict(), f\"results/G{epoch}.pt\")\n",
    "            torch.save(D.state_dict(), f\"results/D{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ee5142ba8a2589df39b0df03e82f50c3ae535c49aaf7d83abad1a0d572c7e37"
  },
  "kernelspec": {
   "display_name": "tvmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
